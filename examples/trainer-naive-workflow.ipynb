{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljvm/Documents/ThinkingMachines/christmAIs/venv/lib/python3.6/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/ljvm/Documents/ThinkingMachines/christmAIs/venv/lib/python3.6/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "from christmais import FastTextWrapper\n",
    "from nltk.corpus import brown # or any other corpus\n",
    "from christmais import (get_fasttext_pretrained, Artist)\n",
    "from christmais import Predictor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading FastTextWrapper object from /tmp/brown_fasttext.model\n",
      "WARNING:christmais.embedder:/tmp/brown_fasttext.model not found, will train FastText with brown corpus...\n",
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
      "INFO:gensim.models.word2vec:collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 15173 unique words (27% of original 56057, drops 40884)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 1095086 word corpus (94% of original 1161192, drops 66106)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 56057 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 42 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 781596 word corpus (71.4% of prior 1095086)\n",
      "INFO:gensim.models.fasttext:estimated required memory for 15173 words, 91240 buckets and 8 dimensions: 14921156 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.fasttext:Total number of ngrams is 91240\n",
      "INFO:gensim.models.base_any2vec:training model with 3 workers on 15173 vocabulary and 8 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 26.29% examples, 208870 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 50.98% examples, 211913 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 82.18% examples, 218684 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 1161192 raw words (781781 effective words) took 3.6s, 215784 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 26.29% examples, 209848 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 50.98% examples, 210807 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 82.18% examples, 218803 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 1161192 raw words (781981 effective words) took 3.6s, 216679 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 23.64% examples, 193426 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 47.85% examples, 203096 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 75.14% examples, 209010 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 1161192 raw words (781722 effective words) took 3.8s, 207203 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 18.20% examples, 146449 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 39.31% examples, 157406 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 58.31% examples, 161587 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 88.13% examples, 170759 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 1161192 raw words (781436 effective words) took 4.5s, 172468 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 21.75% examples, 175689 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 44.52% examples, 182552 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 68.78% examples, 191755 words/s, in_qsize 0, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 100.00% examples, 191359 words/s, in_qsize 0, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 1161192 raw words (781464 effective words) took 4.1s, 191263 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 5805960 raw words (3908384 effective words) took 19.6s, 199043 effective words/s\n",
      "INFO:gensim.utils:saving FastTextWrapper object under /tmp/brown_fasttext.model, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute vectors_vocab_norm\n",
      "INFO:gensim.utils:not storing attribute vectors_ngrams_norm\n",
      "INFO:gensim.utils:not storing attribute buckets_word\n",
      "INFO:gensim.utils:saved /tmp/brown_fasttext.model\n"
     ]
    }
   ],
   "source": [
    "model = get_fasttext_pretrained(load=True)\n",
    "seed = model.transform(\"Thinking Machines Data Science\")\n",
    "artist = Artist(seed, dims=(224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = artist.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File labels.json not found in /tmp/, attempting download from https://s3.amazonaws.com/outcome-blog/imagenet/labels.json\n",
      "INFO:root:File labels.json stored in /tmp/labels.json\n"
     ]
    }
   ],
   "source": [
    "p = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists = [Artist(seed, (224,224)) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<christmais.drawsys.Artist at 0x7f286854a748>,\n",
       " <christmais.drawsys.Artist at 0x7f286854a710>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d46d8>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d4ba8>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d44e0>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d4a20>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d4630>,\n",
       " <christmais.drawsys.Artist at 0x7f28687d40f0>,\n",
       " <christmais.drawsys.Artist at 0x7f286854ae10>,\n",
       " <christmais.drawsys.Artist at 0x7f286854a978>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [artist.draw() for artist in artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../christmais/predictor.py:220: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = sm(fc_out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 52.6 ms, total: 26.8 s\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitness = [p.predict(img, target='iron')[0] for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.5287877e-05,\n",
       " 0.0002812682,\n",
       " 1.3815869e-05,\n",
       " 0.00023506542,\n",
       " 2.3766404e-05,\n",
       " 0.00037053306,\n",
       " 0.00031545517,\n",
       " 0.0002697155,\n",
       " 5.80034e-06,\n",
       " 0.000509705]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "christmAIs",
   "language": "python",
   "name": "christmais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
